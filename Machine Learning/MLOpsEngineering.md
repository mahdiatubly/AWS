## Introduction to MLOps

* To implement quality control measures at the model registration step. If a model meets baseline performance metrics, it can be registered with a model registry. A model registry can be used as a quality gate. A model registry is a mechanism that is used to:
  * Catalog models for production.
  * Manage model versions.
  * Associate metadata, such as training metrics, with a model.
  * Manage the approval status of a model.
 

## Initial MLOps

* Deep Learning Containers provide optimized environments with TensorFlow and MXNet, Nvidia CUDA (for GPU instances), and Intel MKL (for CPU instances) libraries.
* SageMaker Studio environments do not support the elevated permissions needed to access the Docker daemon for building a Docker image. A separate build environment is needed to extend or build containers. The Amazon SageMaker Studio Image Build Command Line Interface (CLI) lets you build Amazon SageMaker-compatible Docker images directly from your Amazon SageMaker Studio environments.
* The build CLI automatically sets up a reusable build environment that you interact with by using high-level commands. The CLI orchestrates the build workflow using AWS CodeBuild and returns a link to your Amazon Elastic Container Registry (Amazon ECR) image location.
* Accessing the Docker daemon within SageMaker Studio:
  1. Assume execution role
  2. Package directory and upload to S3 bucket
  3. Build the Docker image using AWS CodeBuild
  4. Push the image to the ECR repository and return URI
 
* Training and inference containers in SageMaker must adhere to a specific folder structure. SageMaker-provided containers already have this folder structure in place. Any container that you extend or build new, must also follow this structure. A SageMaker model training container requires a parent directory named ‘/opt/ml’. Within that directory are subdirectories named: code, input, checkpoints, output, and model. SageMaker training uses environment variables to define storage paths.
  * code: You store the custom decision tree algorithm, ‘train.py,’ in this directory. The source container has a root directory containing a dockerfile, build_and_push.sh, and a subdirectory named ‘decision_trees’. This subdirectory contains the custom training algorithm, train.py
  * input: When you run a model training job, the SageMaker container uses SM_INPUT_DIR, which defaults to the /opt/ml/input/ directory. The JSON files that configure the hyperparameters for the algorithm and the resources used for distributed training are stored in the opt/ml/input/config directory. The input directory also contains a subdirectory within the /opt/ml/input/data directory for each channel of training data stored in Amazon S3.
  * checkpoints: If you use checkpointing, Amazon SageMaker saves checkpoints locally in the checkpoint_local_path, /opt/ml/checkpoints, and synchs them to the checkpoint_s3_uri.
  *  outputs: The outputs of a training job are sent from /opt/ml/output/data to the output data uri in S3 as output.tar.gz.
  *  The script must write the model generated by your algorithm to SM_MODEL_DIR, which defaults to /opt/ml/model/. When training is finished, the final model artifact in the /opt/ml/model folder is written to the output data uri in S3 as model.tar.gz.
  *  ../WORKDIR/: Training job operations that are distributed across multiple containers use the WORKDIR/.



