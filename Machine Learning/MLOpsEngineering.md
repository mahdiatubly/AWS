## Introduction to MLOps

* To implement quality control measures at the model registration step. If a model meets baseline performance metrics, it can be registered with a model registry. A model registry can be used as a quality gate. A model registry is a mechanism that is used to:
  * Catalog models for production.
  * Manage model versions.
  * Associate metadata, such as training metrics, with a model.
  * Manage the approval status of a model.
 

## Initial MLOps

* Deep Learning Containers provide optimized environments with TensorFlow and MXNet, Nvidia CUDA (for GPU instances), and Intel MKL (for CPU instances) libraries.
* SageMaker Studio environments do not support the elevated permissions needed to access the Docker daemon for building a Docker image. A separate build environment is needed to extend or build containers. The Amazon SageMaker Studio Image Build Command Line Interface (CLI) lets you build Amazon SageMaker-compatible Docker images directly from your Amazon SageMaker Studio environments.
* The build CLI automatically sets up a reusable build environment that you interact with by using high-level commands. The CLI orchestrates the build workflow using AWS CodeBuild and returns a link to your Amazon Elastic Container Registry (Amazon ECR) image location.
* Accessing the Docker daemon within SageMaker Studio:
  1. Assume execution role
  2. Package directory and upload to S3 bucket
  3. Build the Docker image using AWS CodeBuild
  4. Push the image to the ECR repository and return URI
 
* Training and inference containers in SageMaker must adhere to a specific folder structure. SageMaker-provided containers already have this folder structure in place. Any container that you extend or build new, must also follow this structure. A SageMaker model training container requires a parent directory named ‘/opt/ml’. Within that directory are subdirectories named: code, input, checkpoints, output, and model. SageMaker training uses environment variables to define storage paths.
  * code: You store the custom decision tree algorithm, ‘train.py,’ in this directory. The source container has a root directory containing a dockerfile, build_and_push.sh, and a subdirectory named ‘decision_trees’. This subdirectory contains the custom training algorithm, train.py
  * input: When you run a model training job, the SageMaker container uses SM_INPUT_DIR, which defaults to the /opt/ml/input/ directory. The JSON files that configure the hyperparameters for the algorithm and the resources used for distributed training are stored in the opt/ml/input/config directory. The input directory also contains a subdirectory within the /opt/ml/input/data directory for each channel of training data stored in Amazon S3.
  * checkpoints: If you use checkpointing, Amazon SageMaker saves checkpoints locally in the checkpoint_local_path, /opt/ml/checkpoints, and synchs them to the checkpoint_s3_uri.
  *  outputs: The outputs of a training job are sent from /opt/ml/output/data to the output data uri in S3 as output.tar.gz.
  *  The script must write the model generated by your algorithm to SM_MODEL_DIR, which defaults to /opt/ml/model/. When training is finished, the final model artifact in the /opt/ml/model folder is written to the output data URI in S3 as model.tar.gz.
  *  ../WORKDIR/: Training job operations that are distributed across multiple containers use the WORKDIR/.
 
* SageMaker downloads data from the S3 bucket to the container's file system. When the training job is complete, it uploads the trained model artifact from the local folder to the specified location in S3 and stops the training container.
* When creating your own custom containers for inference, SageMaker requires that you locate your inference code in specific directories. You can host a trained model for inference or batch transform. In both cases, the trained model is loaded into the container in the same folder to which they were written during training.
* You must also add the code required to perform inference using a web application. You place the following files in the /opt/ml/code directory:
   * serve.py – the program started when the container is created for hosting. It launches the gunicorn server which runs multiple instances of the web application defined in predictor.py.
   * predictor.py – the program that implements the web server and the decision tree predictions for this app.
   * webserver.conf – the configuration file for the front end.
   * wrapper.py – is a small wrapper used to invoke the web application.
 
* You can use pre-built containers to deploy your custom models or models that have been trained in a framework outside SageMaker:
  * First you convert the model into a format that is readable by the SageMaker model constructor for the corresponding framework.
  * Second, create a model in SageMaker Inference by pointing to model artifacts stored in Amazon S3 and a container image.
  * Finally, deploy the model to a SageMaker inference endpoint. You will need to choose the number of instances and the type of instances at which to deploy our model.
* The SageMaker Training Toolkit and the SageMaker Inference Toolkit. These two toolkits define the information the container needs to manage training and inference on Amazon SageMaker.
* Domain configurations: An Amazon SageMaker Domain consists of storage resources, a list of authorized users, and a variety of security, application, policy, and Amazon VPC configurations. Users within a Domain can share notebook files and other artifacts with each other. An account can have multiple Domains.
* User profile: A user profile represents a single user within a Domain. It is the main way to reference a user for the purposes of sharing, reporting, and other user-oriented features.
* Spaces: Spaces are used to manage the storage and resource needs of some Amazon SageMaker Studio applications. Each space has a 1:1 relationship with an instance of an application. Spaces can be either private or shared.
  * Private: Private spaces cannot be shared with other users.
  * Shared: Shared spaces are accessible by all users in the domain.
 
* Apps: An app represents an application that supports the reading and execution experience of the user’s notebooks, terminals, and consoles. The type of app can be JupyterServer, KernelGateway, RStudioServerPro, or RSession.
SageMaker offers various setup options optimized for different organizational needs:

1. **Quick Setup**
   - The fastest option to start using SageMaker Studio as an individual user.
   - Utilizes AWS Identity and Access Management (IAM) authentication with auto-generated defaults.
   - Helpful for single-user domains or first-time users exploring SageMaker.
   - Account configuration can be updated later.

2. **Standard Setup**
   - Requires the most configuration and offers the most options for customization.
   - Suitable for administrators managing large user groups.
   - Includes VPC configuration and setup for Single Sign-On or IAM Identity Provider.

3. **Templated SageMaker Domain in AWS Service Catalog**
   - Enables centralized management of AWS resources.
   - Data scientists can access the SageMaker Domain directly from a preconfigured environment through the AWS Service Catalog.
   - Ideal for organizations needing to comply with strict regulatory guidelines, such as HIPPA or Payment Card Industry (PCI).
   - Activates automated provisioning of environments preconfigured to comply with necessary policies.

* SageMaker JumpStart: Example notebooks and pre-trained models that you can use to fine-tune your own data.
* Notebook sharing: Share a snapshot of your notebook that team members can copy and work on their own version.  To share your latest version, you must create a new snapshot and then share it as a copy.
*  Shared spaces: A shared space consists of a shared JupyterServer application and a shared directory. Shared spaces facilitate collaboration in real-time. Co-editing is most effective for small groups. 
* SageMaker Projects: Templates you can use for orchestrating ML Ops and continuous integration and delivery (CI/CD) workflows. Orchestration includes managing dependencies, code repositories, build reproducibility, and artifact sharing.
* Encryption - SageMaker uses an AWS Key Management Service (AWS KMS) key to encrypt your Amazon EFS and Amazon Elastic Block Store (Amazon EBS) file systems by default. You can select a customer-managed key instead.
* Authentication – Choose between AWS IAM or AWS IAM Identity Center (successor to AWS SSO). Authenticate with AWS IAM to provide access to the Amazon SageMaker console or AWS CLI. You can use AWS IAM Identity Center to centralize identity management and provide a consistent user sign-in experience.
* Use Amazon SageMaker Role Manager to build and manage persona-based IAM roles for common machine learning needs directly through the Amazon SageMaker console. Amazon SageMaker Role Manager provides three preconfigured role personas with suggested permissions. Permissions are predefined for common ML activities. You can use the activities to create and maintain roles for personas unique to your business needs. These personas include the following:
  * Data Scientist persona – Use this persona to configure permissions to perform general machine learning development and experimentation in a SageMaker environment.
  * MLOps persona – Use this persona to configure permissions for operational activities.
  * SageMaker compute persona – Use this persona to configure permissions to your compute resources, such as the ability to interact with other AWS services.
 
* If the default environment does not meet your needs, consider using lifecycle configuration scripts. Lifecycle configurations are shell scripts triggered by SageMaker Studio lifecycle events, such as creating a new SageMaker Studio notebook or starting up a SageMaker Studio notebook. You can use these shell scripts to:
  * Install packages or sample notebooks on your notebook instance
  * Installing JupyterLab extensions
  * Preloading datasets
  * Configure git credentials with AWS Secrets Manager
  * Setting up source code repositories.
  * Running other shell scripts
  * Configure shutdown after idle timeout
  * To access AWS services from your notebook.
 
* Lifecycle configuration scripts can consist of up to 16384 characters and can run up to 5 minutes. To run a script as an OS process beyond the 5-minute timeframe, you can run the commands using nohup. Lifecycle configuration scripts log information to Amazon CloudWatch Logs under the under the log stream <DomainId>/<UserProfileName>/<AppType>/<AppName>. These logs are helpful for troubleshooting the lifecycle configuration job.
* Making experimentation environments self-service: AWS Service Catalog enables you to create and manage collections of logical IT products and services configured and parameterized as templates. These IT template products and services encompass various resources, including machine learning experimentation resources such as SageMaker Domains and SageMaker Studio User Profiles. With AWS Service Catalog, you can centrally manage commonly deployed IT services, facilitating consistent governance and compliance adherence. This platform empowers users to swiftly deploy only the approved IT services they require, streamlining operations and enhancing productivity.

## Repeatable MLOps
* Repository options on AWS:
  * AWS CodeCommit: A secure, highly scalable, fully managed source control service that hosts private Git repositories
  * Amazon SageMaker Feature Store: A fully managed, purpose-built repository to store, share, and manage features for machine learning (ML) models
  * Amazon SageMaker Model Registry: Catalogs and manages model versions
  * Third-party repository option: For example, GitHub and Bitbucket.
 
* ML workflow automation on AWS:
  * SageMaker provides a model-building pipeline through the SageMaker Pipelines SDK. With SageMaker Pipelines, you can create, automate, and manage end-to-end ML workflows at scale.
  * AWS Step Functions provide a serverless way to orchestrate pipelines, including ML-based ones.
  * Amazon Managed Workflows for Apache Airflow (MWAA) orchestrates your workflows by using Directed Acyclic Graphs (DAGs) written in Python.+
  * Third-party solutions include MLflow and Kubeflow. MLflow is an open-source platform to manage the ML lifecycle, including experimentation, reproducibility, deployment, and a central model registry. Kubeflow is a platform for building and deploying portable, scalable ML workflows, based on Docker containers. Kubeflow is the ML toolkit for Kubernetes.

* Amazon S3 provides versioning to protect data assets. When activated, Amazon S3 versioning will retain multiple copies of a data asset. When an asset is updated, prior versions of the asset will be retained and can be retrieved at any time. If an asset is deleted, the last version of it can be retrieved.
* SageMaker Data Wrangler, a visual data preparation tool. Data Wrangler is integrated into the SageMaker Studio UI. With the SageMaker Data Wrangler data selection tool, you can quickly access and select your tabular and image data from a wide variety of popular sources. For example, you can use Amazon S3, Amazon Athena, Amazon Redshift, AWS Lake Formation, Amazon EMR, Snowflake, and Databricks Delta Lake.
* Amazon AppFlow is a fully managed integration service. It helps you securely transfer data between software-as-a-service (SaaS) applications and AWS services such as Amazon S3 and Amazon Redshift.
* AWS Lake Formation data lake offers the features that are required to serve as the unified repository for all of your data securely. With a large number of Data Catalog resources, Lake Formation tag-based access control (LF-TBAC) is the recommended method to use to grant Lake Formation permissions. Principals must access data resources through an integrated service like SageMaker Data Wrangler.
* Features represent relevant attributes or properties that your model uses for training and to make predictions.
* With a feature store, you generate features by using raw data. Whenever the features are processed, the feature is committed to a central feature store, which serves as the centralized repository. Thus, it helps to eliminate redundancy in feature engineering pipelines and optimizes the ML development cycle. ML developers can easily search the centralized store to discover features to use for training or inference.
* SageMaker Feature Store organizes features in groups. You can think of a feature group as a data table and a feature as a column in the table. You can use the Amazon SageMaker Feature Store API or Amazon SageMaker Studio to add features to your feature group. When you add a feature to the feature group, you're effectively adding a column to the table. The features that you've added don't have any data. You can think of a record as a row in the data table. You can add new records to the feature group or overwrite them. Using the Feature Store, you can reconstruct all of the supporting features that are connected to that record as of the time of the timestamp. Therefore, the data is always time-consistent.

* Amazon SageMaker Feature Store Spark is a Spark connector that connects the Spark library to the Feature Store. Feature Store Spark simplifies data ingestion from Spark DataFrames to feature groups. Feature Store supports batch data ingestion with Spark, using your existing ETL pipeline, on Amazon EMR, GIS, an AWS Glue job, an Amazon SageMaker Processing job, or a SageMaker notebook.

* SageMaker Feature Store offers the following modes for utilizing Feature Store data:
  * **Online Mode**: Retrieves the most recent record with low-latency reads, suitable for high-throughput predictions. Requires a feature group stored in an online store.
  * **Offline Mode**: Stores all historical records, ideal for training and batch inference with large data streams. Requires a feature group stored in an offline store, utilizing Amazon S3 bucket for storage and supporting data retrieval via Athena queries.
  * **Online and Offline Mode**: Integrates both online and offline modes, ensuring synchronization between offline and online datasets to maintain model accuracy. This mode is crucial for preventing discrepancies that could affect model performance.
 
* SageMaker Feature Store organizes features into groups based on parameters or business entities. It supports both streaming and batch inference and allows easy management across ML applications in SageMaker Studio. Different entity types like orders or customers can have their own feature groups, and security is enhanced through tags and permission controls.
* If you trained your model in SageMaker, the model artifacts are saved as a single compressed .tar file in Amazon S3. As with data, versioning in Amazon S3 is a means of keeping multiple variants of an object in the same bucket, such as *.tar.gz files.
* To store and track versions for model training and inference container images, you can use the Amazon Elastic Container Registry (Amazon ECR).
* With a model registry, you can track model versions and their metadata in a central repository. 
The model registry organizes model package groups, each containing multiple versions of a model package. It tracks all model versions trained for a specific problem within a model group. Adding a trained model to the registry creates a new model version within the group, which can be marked as approved or rejected based on predefined acceptance criteria set by the team building the models.
* Each model package in a model group represents a trained model, with its version denoted by a numerical value starting at 1 and incremented with each addition. These versioned model packages in the registry must be linked to a specific model group. A model version must comprise both the model artifacts (trained weights) and the inference code. By defining attributes, you can use tags on both resources and user entities to create tag-based permissions policies. You don’t have to update these policies even as you add new subsidiaries or team members.
* One way to accomplish this standardization is to establish separate repositories for the building and testing, and deployment pipelines. The building and training repository is divided into three main folders:
  *  Algorithms – Typically, data scientists develop the code for each step of the ML pipelines in the algorithms root folder. The steps can be grouped in preprocessing, training, batch inference, and postprocessing (evaluation). In each group, multiple steps can be defined in corresponding subfolders. These folders contain a folder for the unit tests (including optional inputs and outputs), the main functions, and the readme. They also contain a Docker file in case of a custom container need. In addition to main, multiple code files can be hosted in the same folder. Common helper libraries for all of the steps can be hosted in a shared library folder. The data scientists are responsible for the development of the unit tests because they own the logic of the steps. ML engineers are responsible for the error handling enhancement and test coverage recommendation.
  *  ML pipelines – After you develop the source code and tests of each step, the next step is to define the SageMaker pipelines in another root folder. Each ML pipeline definition is placed in a subfolder that contains the .py file. In this example, the training subfolder is shown. This subfolder also contains a JSON or .yaml file for input parameters, such as hyperparameter ranges. A readme file to describe the ML pipelines is necessary.
  *  Notebooks – This folder hosts the origin notebooks that the data scientist used during experimentation.
* The deployment repository consists of three main parts:
  *  Inference configuration – This folder contains the configuration of real-time endpoints or batch inference per development environment, such as instance types.
  *  Application infrastructure (app_infra) – Hosts the source code of the infrastructure that is required to run the inference, if necessary. This code might be a triggering mechanism that uses Amazon EventBridge, Amazon API Gateway, AWS Lambda functions, or SageMaker Pipelines.
  *  Tests – Consists of multiple subfolders depending on the customer testing methodology. As the minimum set of tests, the following tests are suggested: • An integration test (end-to-end run of the inference including application infrastructure) • A stress test (examine edge cases) • ML tests (such as the distribution of confidence scores or probabilities)
 
* Amazon SageMaker can connect to AWS CodeCommit, GitHub, GitHub Enterprise, and Bitbucket to pull source code.
* By integrating AWS CodeCommit with Amazon SageMaker, you can manage your machine learning codebase, track changes, and promote collaboration.
* If the repository that you are connecting to is private, store the credentials that are used to authenticate to the repository in AWS Secrets Manager.
* A pull request is the primary way that you and other repository users can review, comment, and merge code changes from one branch to another. CodeCommit is integrated with AWS CloudTrail, a service that provides a record of actions by a user, a role, or an AWS service in CodeCommit. CloudTrail captures all API calls for CodeCommit as events, including calls from the CodeCommit console, your Git client, and code calls to the CodeCommit APIs.
* Amazon SageMaker Pipelines is a purpose-built fully managed service workflow orchestration solution for ML. With SageMaker Pipelines, you can create, reuse, and share ML workflows at scale. You can create ML workflows by using a Python SDK and visualize them in SageMaker Studio. You can view, track, and run SageMaker Pipelines from the SageMaker Studio interface. With SageMaker Pipelines, you can track the history of your data within each pipeline run.
* You can introduce variables into your pipeline definition by using parameters. You can use parameters for custom pipeline runs and schedules without having to modify the pipeline definition. You can reference your parameters throughout your pipeline definition. Parameters have a default value, which you can override by specifying parameter values when starting a pipeline execution. All parameters that are used in step definitions must be defined in your pipeline definition.
* Passing the outputs, or properties, of one step to the next step creates a data dependency. You can also define custom dependencies between steps. SageMaker uses these dependencies to build a Directed Acyclic Graph (DAG).
*  An Amazon SageMaker Model Building Pipelines instance is composed of a name, parameters, and steps. Pipeline names must be unique within an (account, region) pair.
*   Step_cond is defined as a conditional check. It calls the code to register the model only if the metrics from the evaluation step meet the defined threshold.
*   Note that pipeline.upsert(role_arn=role) creates a new pipeline if one doesn't exist, or updates the pipeline definition for an existing pipeline. It also associates an AWS Identity and Access Management (IAM) role. This role should have the right permissions to execute all of the steps that are involved in the pipeline. The role for the SageMaker instance that creates the pipeline must have the iam:PassRole permission for the pipeline execution role in order to pass it. Finally, as soon as the pipeline has been defined, it can be run, or rerun, by calling pipeline.start().
*  Property files and JsonGet – Use property files to store information from the output of a processing step. This method is particularly useful when analyzing the results of a processing step to decide how a conditional step should be executed. The JsonGet function processes a property file and provides the ability to use JsonPath notation to query the property JSON file.
*  Caching steps – With SageMaker Pipelines, you can configure steps for caching. Step caching is off by default. When a step is enabled for caching, you must provide the key attribute values that determine whether the step can be reused within an expiration time period. Thus, you can reuse the output from previous step executions of the same step in the same pipeline without having to run the step again.
*  Selective execution – Use selective execution to run your selected steps in a pipeline while avoiding the need to rerun the entire pipeline. Selective execution is useful when you must undertake multiple experimentation phases, especially when some steps are time-consuming or costly to run.
*  Retry policy – Retry policies help you to automatically retry your SageMaker Pipelines steps after an error occurs. Any pipeline step can encounter exceptions, and exceptions happen for various reasons. In some cases, a retry can resolve these issues. With a retry policy for pipeline steps, you can choose whether to retry a particular pipeline step or not.
*  GPU instances are effective choices for training ML frameworks such as TensorFlow, PyTorch, MXNet, and XGBoost. They are also effective for training Deep Learning models with neural networks. Select from a range of GPU instances that balance performance and cost considerations.
*  AWS Trainium instances are optimized for deep learning with large model
*  Deployment approval gate – After the package is created and verified, the next step is an approval gate for deployment to the next environment. It is possible to automate this approval, but it is common to have humans in the loop at this point of the lifecycle. Leaders in DevOps, business leaders, or data scientists determine that it is the right time to deploy the package.
*  If you use SageMaker for real-time inference hosting, you need to create a SageMaker endpoint. The endpoint is the destination end of an API communication channel. Client application APIs send inference requests to this channel, and predictions and other responses are returned from it.
*  Endpoint: an endpoint could represent a pipeline of logical steps to serve the inference. You can create endpoints manually or by using AWS CloudFormation templates or other automation tools. Even though an IP address is required for client communications, the IP address is not considered part of the endpoint. Instead, it is attached to the endpoint. Also, an endpoint is often defined by a URL that could be mapped through the Domain Name System (DNS) to one or more IP addresses. And the IP address that is assigned to the endpoint could change.
* SageMaker Inferentia – For inference at scale, you can use an Inf1 instance with a real-time endpoint. SageMaker Inf1 instances deliver up to 30 percent higher throughput and up to 45 percent lower cost per inference than Amazon EC2 G4 instances. Inf1 instances are built to support machine learning inference applications by using the AWS Inferentia chips. You can compile models to run on Inf1 instances by using Amazon SageMaker Neo. High throughput at lower cost than GPUs. Ideal for models that AWS Neuron SDK supports.
* Tpically, a client application sends requests to the SageMaker HTTPS endpoint to obtain inferences from a deployed model. You can also send requests to this endpoint from your Jupyter notebook during testing.
* You can deploy multiple variants of a model to the same SageMaker HTTPS endpoint. This practice is useful for testing variations of a model in production.
* To modify an endpoint, you provide a new endpoint configuration. SageMaker implements the changes without any downtime.
* Changing or deleting model artifacts or changing inference code after deploying a model produces unpredictable results. If you need to change or delete model artifacts or change inference code, modify the endpoint by providing a new endpoint configuration. After you provide the new endpoint configuration, you can change or delete the model artifacts that correspond to the old endpoint configuration.
* Practical solutions for production ML workflows:
  * SageMaker provides a model-building pipeline through the SageMaker Pipelines SDK. With SageMaker Pipelines, you can create, automate, and manage end-to-end ML workflows at scale.
  * AWS Step Functions provides a serverless way to orchestrate pipelines, including ML-based ones.
  * Amazon MWAA orchestrates your workflows by using Directed Acyclic Graphs (DAGs) written in Python. SageMaker APIs are used to export configurations for creating and managing Apache Airflow workflows.
  * Kubernetes Orchestration:
    * With SageMaker Operators for Kubernetes using AWS Controllers for Kubernetes (ACK), Kubernetes users can use the Kubernetes API to provision AWS resources.
    * Users can use Amazon SageMaker Components for Kubeflow Pipelines to build and deploy portable and scalable end-to-end ML workflows. Thus, they take advantage of Amazon SageMaker fully managed services in Kubeflow. Kubeflow is a popular open-source machine learning (ML) toolkit for Kubernetes users who want to build custom ML pipelines.
------------------------------------------------------------------------------------------------------------------------------
- Version control – AWS CodeCommit service provides this functionality.
- CI/CD – AWS CodePipeline and AWS CodeBuild provide the CI/CD functionality.
- ML model builder – SageMaker training jobs will provide this functionality.
- ML model deployment – SageMaker model deployment will provide this functionality.
- Monitoring – SageMaker Model Monitor and SageMaker Clarify will provide this functionality.
- Workflow security – IAM roles will provide this functionality.
- Model registry – SageMaker Model Registry will provide this functionality.
- Training data – Amazon S3 will provide this functionality.
- Orchestration – AWS Step Functions will provide this functionality.
- Testing and evaluation – AWS Lambda will provide this functionality.

---------------------------------------------------------------------------------------------------------------------------------------
*  Step Functions are based on state machines and tasks. A state machine is a workflow. A task is a state in a workflow that represents a single unit of work that another AWS service performs. Each step in a workflow is a state. The AWS Step Functions Data Science SDK provides a Python API that can create and invoke Step Functions workflows. You can manage and execute these workflows directly in Python and in Jupyter notebooks.
*  Project templates use AWS CloudFormation templates to create the infrastructure resources. These resources are used by SageMaker Pipelines to orchestrate ML workflows from end to end.
*  The Model Build CodePipeline includes a source stage and a build stage. The source stage gets code from the model build repo in AWS Code Commit. The build stage uses AWS CodeBuild to build and run the Model Build pipeline in SageMaker Pipelines.
*  Always create roles through SageMaker Studio Settings, rather than creating roles manually. For users who use any role other than the domain's execution role to view and use SageMaker-provided project templates, you must grant Project permissions to the individual user profiles.
*  If you choose standard setup to set up your SageMaker domain, turn on the following options when you configure SageMaker Studio settings:
  * Enable Amazon SageMaker project templates and Amazon SageMaker JumpStart for this account.
  * Enable Amazon SageMaker project templates and Amazon SageMaker JumpStart for Studio users.

* Organizations can use the AWS Service Catalog to create and manage catalogs of IT services that are approved for use on AWS.
* Apache Airflow is a platform that you can use to programmatically author, schedule, and monitor workflows. Using Airflow, you can build a workflow for SageMaker training, hyperparameter tuning, batch transform, and endpoint deployment. You can use any SageMaker deep learning framework or Amazon algorithms to perform above operations in Airflow. Benefits of using Airflow and Amazon MWAA to orchestrate ML workflows include:
  * Python-based tool – Developers can programmatically define how tasks are to be done, instead of only what is to be done.
  * Directed acyclic graph (DAG) workflow management – Use the DAG interface for defining and running complex workflows with dependencies. Visualize the DAG workflows to support operations management.
  * Extensibility – Airflow operators provide a structured way to perform common tasks by using reusable modules. These operators provide useful abstraction, repeatability, and an API. These operators are especially valuable because they provide a way to orchestrate sometimes very long-running data pipelines or asynchronous ML processes such as model training.
 
* SageMaker Operators for Kubernetes facilitate the processes for developers and data scientists who use Kubernetes to train, tune, and deploy ML models in SageMaker. You can install these SageMaker Operators on your Kubernetes cluster in Amazon Elastic Kubernetes Service (Amazon EKS). Then, you can use them to create SageMaker jobs natively by using the Kubernetes API and command-line Kubernetes tools such as kubectl.
* A Kubeflow Pipeline component is a set of code that is used to execute one step of a Kubeflow pipeline. Components are represented as a Python module that is built into a Docker image.  components make it fast and straightforward to write pipelines for experimentation and production environments without needing to interact with the underlying Kubernetes infrastructure. SageMaker Components for Kubeflow Pipelines offer an alternative to launching your compute-intensive jobs from SageMaker. The components integrate SageMaker with the portability and orchestration of Kubeflow Pipelines. Using the SageMaker Components for Kubeflow Pipelines (KFP), you can create and monitor your SageMaker resources as part of a Kubeflow Pipelines workflow. Each of the jobs in your pipelines runs on SageMaker instead of the local Kubernetes cluster so that you can take advantage of key SageMaker features. 
* MLflow is an open-source platform to manage the ML lifecycle, including experimentation, reproducibility, deployment, and a central model registry. It includes the following components:
  * Tracking – Record and query experiments, including code, data, configuration, and results.
  * Projects – Package data science code in a format to reproduce runs on any platform.
  * Models – Deploy ML models in diverse serving environments.
  * Registry – Store, annotate, discover, and manage models in a central repository.
 
* You can integrate MLflow with Amazon SageMaker to provide collaborative experiments and model tracking for your ML solution. You can set up a central MLflow tracking server during your ML project. You can host an MLflow tracking server on an EC2 instance. You can also Dockerize it and host the MLflow container on serverless AWS Fargate. On AWS Fargate, you do not need to manage the underlying instance.
* Model governance is a framework that gives systematic visibility into machine learning (ML) model development, validation, and usage. Amazon SageMaker provides purpose-built ML governance tools for managing control access, activity tracking, and reporting across the ML lifecycle.
  * Manage least-privilege permissions for ML practitioners by using Amazon SageMaker Role Manager;  It comes with a set of predefined policy templates for different personas and ML activities. Personas represent the different types of users that need permissions to perform ML activities in SageMaker, such as: Data scientists, MLOps, SageMaker compute role, and Custom role settings. Personas are composed of one or more ML activities to grant permissions. ML activities are a set of permissions to accomplish a common ML task.
  * Create detailed model documentation by using Amazon SageMaker Model Cards.
  * Gain visibility into your models with centralized dashboards by using Amazon SageMaker Model Dashboard.
  * When you train a model, Amazon SageMaker creates a visualization of your entire ML workflow from data preparation to deployment. This visualization is called a model lineage graph and uses entities to represent individual steps in your workflow.
 
* Use VPC endpoints to securely connect to resources. A VPC endpoint in AWS serves the purpose of establishing a private connection between your Amazon Virtual Private Cloud (VPC) and specific AWS services or VPC endpoint services powered by AWS PrivateLink. This private connection allows resources within your VPC to access these services without requiring an internet gateway, NAT gateway, or internet access.

## Reliable MLOps

In the reliable phase of the MLOps maturity model, the automatic testing methodology is introduced, for both the model and invoking infrastructure, in an isolated staging (preproduction) environment that simulates production. After a successful run of the test, the models are deployed to the isolated environment of production. To promote the models among the multiple environments, manual evaluation and approvals are required.
- Integration testing This testing evaluates the functional requirements of the production model. It verifies that all components of an ML pipeline, such as data preprocessing, model training, and deployment, function together correctly. It is crucial for maintaining pipeline integrity and avoiding issues in production.
- Stress and load testing Stress testing assesses an ML system's performance under extreme conditions. It helps identify the system's breaking points and ensures reliability during heavy data loads or high prediction request rates. Amazon SageMaker Inference Recommender is a capability of Amazon SageMaker. It reduces the time required to get ML models in production by automating load testing and model tuning across SageMaker ML instances.

- Model testing validates the performance and robustness of ML models. It checks metrics like accuracy, fairness, and explainability, which ensures that models are trustworthy, unbiased, and interpretably accurate. This module will focus on various testing methods, such as A/B testing and shadow testing.

- Using multiple accounts for reliable MLOps offers many benefits. At a minimum, you should consider an account for development, staging, production, and other.

-  how monitoring contributes to reliable MLOps:
  - Business requirements Measure success criteria (KPIs). This criterion helps to evaluate how well you are meeting your business goals. For example, a video streaming service might monitor data about whether using their ML model has led to an increase in the number of subscribers.
  - Model performance Models are typically trained and evaluated by using historical data. Real-world data might not look like the training data. ML models in production make predictions on real-life data that is not carefully curated like most training datasets. For a complete model performance monitoring solution, consider the following subcategories to evaluate model performance:
    - Data quality
    - Model quality
    - Model bias
    - Feature attribution (explainability)
   
  - Resource utilization Monitor the performance of the infrastructure and the cost that is associated with it. Is the hosting infrastructure appropriate for the demand? Are model latency and graphics processing unit (GPU) utilization within acceptable parameters?
  - Traceability and compliance Monitoring provide an audit trail, which is crucial for troubleshooting, improving model performance, and meeting regulatory requirements.
  - In addition to the previously discussed single model real-time inference hosting option, three other hosting options are available: multiple models, multiple containers, and inference pipeline:
    - With the multiple models option, you can host multiple models on a shared serving container, which helps to reduce hosting costs.
    - With the multiple containers option, you can deploy multiple containers to deploy different models and frameworks. By using direct invocation, you can send a request to a specific inference container that is hosted on a multi-container endpoint.
    - An inference pipeline is an Amazon SageMaker model that consists of a linear sequence of two to fifteen containers. These containers process requests for inferences on data. You use an inference pipeline to define and deploy any combination of pre trained SageMaker built-in algorithms and your own custom algorithms, packaged in Docker containers. You can use an inference pipeline to combine preprocessing, predictions, and postprocessing data science tasks. Inference pipelines are fully managed.
   
- Methods for scaling SageMaker resources:
  - Target tracking: Scale based on a specific Amazon CloudWatch metric (policy) (a predefined metric that is available for use: SageMakerVariantInvocationsPerInstance is the average number of times per minute that each instance for a variant is invoked)
  - Step: Advanced type of scaling. Define additional policies to dynamically adjust instances based on the size of the alarm breach (policy)( It helps you to configure a more aggressive response when demand reaches a certain level.).
  - Scheduled: Supports a one-time schedule, a recurring schedule, or cron expressions (policy).
  - On-demand: Increase or decrease the number of instances manually (manual).
 
- Cooldown refers to the minimum amount of time that must elapse after a scaling event (adding or removing instances) before Auto Scaling initiates another scaling action.
- Shared services account is used to deploy and operate common services and resources within an enterprise ML platform. Common resources—shared code repositories, library package repositories, automation pipelines, Docker image repositories, service catalog factory, and model repository—can be hosted in the shared services account.
- Central management: AWS Organizations provides tools to centrally govern and manage your cloud environment. The number and organization of accounts that best meets your needs will depend on your organizational approach and your use case.
- It is a best practice to run ML workloads with account-level isolation across development, test, and production workloads. AWS accounts serve as the fundamental security boundary in AWS. They serve as a resource container that provides a useful level of isolation. You can use an Amazon EventBridge rule to start AWS CodePipeline in the development account. The pipeline can deploy the hosting infrastructure into a target environment such as staging or production. The job would require cross-account authorization to launch resources in the target account.
- Operating model is a framework that brings people, processes, and technologies together to help organizations deliver business value in a scalable, consistent, efficient manner. The ML operating model provides a standard product development process for teams across the organization. Three models are available for implementing the operating model:
  - Centralized data science team operating model, data science activities are centralized within a single team or organization. A shared services account provides tooling that supports MLOps requirements across a data science team. Separate dev, preproduction, and production accounts share the ML workload for all data science teams. Governance policies isolate workloads between data science teams.
  - Decentralized data science team operating model, each ML team operates independently. Data science activities are distributed as each team provisions, manages, and governs their ML accounts and resources. Centralized observability and data governance accounts support data governance and audit management requirements. Consider resource isolation from one ML team to another. They break out ML workloads by organizational unit access patterns.
  - Federated operating model, each data science or ML team gets their own set of tooling, development, preproduction, and production accounts. This approach provides physical isolation of ML resources. Each team can scale independently without impacting other teams.
 
- Regardless of the operating model that you choose for your ML solution, AWS has identified best practices for organizing your AWS environment. These best practices augment and support AWS Well-Architected Framework:
  - Use AWS Control Tower for setup, management, and governance of your accounts. (is a service offered by Amazon Web Services (AWS) that helps organizations set up and govern secure, multi-account AWS environments.)
  - Use guardrails and service control policies (SCPs) to enforce best practices for each environment type. SCPs essentially set the maximum permissions that can be granted within an account. IAM policies within the account can further restrict permissions, but cannot exceed the limits set by the SCP. Limit infrastructure management access to administrators.
  - Set up account-level isolation across development, test, and production workloads.
  - Stream ML workload logs to a log archive account, and then filter and apply log analysis in an observability account.
  - Run a centralized governance account for provisioning, controlling, and auditing data access.
 
- Shadow: In this approach, the production model and candidate replacement model are tested with live data side-by-side, but on a dedicated environment for testing. Live production data is feeding these tests, but the responses do not impact the production system. Shadow testing provides production safety because the inference predictions do not impact the production system.
- SageMaker multi-variant endpoints provide two methods for testing ML models, or you can invoke a specific variant directly for each request:
  - Specifying traffic distribution – You can distribute endpoint invocation requests across multiple production variants by providing the percentage of traffic distribution for each variant.
  -  Invoking specific variants – You can test multiple models by invoking specific models for each request. Configure your application to specify a specific TargetVariant parameter when you call InvokeEndpoint during a user session. SageMaker targets the production variant that you specify to process the request. This targeted routing overrides the traffic distribution specified in the endpoint configuration.
 
- Deployment guardrails are a set of model deployment options in Amazon SageMaker Inference to update your machine learning models in production. SageMaker supports two types of deployments to update models in production: blue/green deployments and rolling deployments.
-  The available traffic shifting modes for blue/green deployments are all at once, canary (Traffic shifts in two steps), and linear (A fixed portion of the traffic shifts in a pre-specified number of equally spaced steps). Amazon CloudWatch alarms are a prerequisite for using baking periods in deployment guardrails. You can only use the auto-rollback functionality in deployment guardrails if you set up CloudWatch alarms that can monitor an endpoint.  If you do not have any CloudWatch alarms set up to monitor your endpoint, then the auto-rollback functionality does not work during your deployment.
-  The baking period feature helps you to monitor the performance and functionality of your new instances before terminating your old instances. Thus, it ensures that your new fleet is fully operational.
- The portion of your green fleet that turns on to receive traffic is called the canary, and you can choose the size of this canary. The canary size should be less than or equal to 50 percent of the new fleet's capacity. After the baking period finishes and no pre-specified CloudWatch alarms are activated, the remaining traffic shifts from the old (blue) fleet to the green fleet.
- Rolling deployments gradually replace the previous deployment of your model version with the new version by updating your endpoint in configurable batch sizes. The traffic shifting behavior of rolling deployments is similar to the linear traffic shifting mode in blue/green deployments. However, rolling deployments provide you with the benefit of reduced capacity requirements when compared to blue/green deployments. With rolling deployments, fewer instances are active at a time. You have more granular control over how many instances you want to update in the new fleet. You should consider using a rolling deployment instead of a blue/green deployment if you have large models or a large endpoint with many instances.
- You can update the approval status of a model version by using the AWS SDK for Python (Boto3) or by using Amazon SageMaker Studio. You can also update the approval status of a model version as part of a condition step in a SageMaker pipeline.

### Monitoring MLOps

- Endpoint Invocation metrics include:
  - Invocation4XXErrors and Invocation5XXErrors – The number of InvokeEndpoint requests where the model returned a 4xx HTTP response code or a 5xx HTTP response code.
  - Invocations – The number of InvokeEndpoint requests sent to a model endpoint.
  - InvocationsPerInstance – The number of invocations sent to a model, normalized by InstanceCount in each ProductionVariant.
  - ModelLatency – The interval of time (in microseconds) taken by a model to respond as viewed from SageMaker. This interval includes the local communication times taken to send the request and to fetch the response from the container of a model. It also includes the time taken to complete the inference in the container.
  - OverheadLatency – The interval of time (in microseconds) added to the time that is taken to respond to a client request by SageMaker overheads. This interval is measured from the time SageMaker receives the request until it returns a response to the client, minus the ModelLatency.
 
- CodeWhisperer: artificial intelligence (AI)-powered code generator for IDEs and code editors.
- Business goals and KPIs – An important part of planning a ML solution is identifying the success criteria, or key performance indicators (KPIs). You can use these KPIs to understand how well you are meeting your business goals.
- Hosting infrastructure – Monitor the performance and cost of the hosting infrastructure. Is the hosting infrastructure appropriate for the demand? Are model latency and GPU utilization within acceptable parameters?
- Model performance – Measure how well your model is generalizing against unseen data as measured by quality metrics such as accuracy, precision, recall, and F1 score.
- Data Quality: ML models in production need to make predictions on real-life data that is not carefully curated like most training datasets. The statistical nature of the data your model receives in production might drift away from the nature of the baseline data it was trained on. In that case, the model begins to lose accuracy in its predictions.
- Model quality monitoring jobs compute different metrics depending on the ML problem type, As  mean-squared error (MSE), root-mean-square error (RMSE), mean absolute error (MAE), or r-squared (R2) with regression problems.
- Data quality drift – Production data distribution differs from data that is used for training.
- Model quality drift – Predictions that a model makes differ from actual ground truth labels that the model attempts to predict.
- Feature attribution drift – The contribution of individual features to model predictions differs from the baseline that was established during model training.
- Bias drift – Bias was introduced because of change in production data distribution or application. (The production dataset differs from the training set)
- feature attribution reports provide insights into whether a particular model input, or feature, has more influence than expected on overall model behavior. SageMaker Model Monitor integration with SageMaker Clarify provides explainability tools for deployed models hosted in SageMaker. SageMaker Clarify offers a scalable implementation of Shapley Additive xPlanations (SHAP), based on the Shapley value from cooperative game theory. The model explainability monitor assigns each feature an importance value for a particular prediction. It calculates a normalized, global SHAP score for the model which compares feature attribution for live production data with the baseline.
- Bias differs from variance, which is the level of small fluctuations or noise common in complex data sets. Bias tends to cause model predictions to overgeneralize, and variance tends to cause models to undergeneralize. Increasing variance is one method for reducing the impact of bias. Amazon SageMaker Clarify detects potential bias during data preparation, after model training, and in a deployed model by examining attributes that you specify. SageMaker Clarify bias detection capabilities are integrated into Amazon SageMaker Model Monitor. When SageMaker detects bias beyond a certain threshold, it automatically generates metrics that you can view in Amazon SageMaker Studio and through Amazon CloudWatch metrics and alarms.
- Amazon SageMaker Model Monitor continuously monitors the quality of Amazon SageMaker machine learning models in production. Model Monitoring provides visibility into data and model quality and can alert you to problems in your application.
- If you are monitoring a real-time endpoint, you can also visualize metrics in Amazon SageMaker Studio. You can select a specific monitoring job to view details. You can create charts in SageMaker Studio to visualize the baseline and captured values for metrics that are calculated by the monitoring job.
- With SageMaker Model Monitor, the suggest_baseline command starts a SageMaker processing job. The output of the baseline job consists of two files:
  - constraints.json – Lists the features with inferred data type, and completeness for each.
  - statistics.json – Provides statistical analysis of each feature in the dataset. Data includes count, missing data, mean, sum, standard deviation, minimum, maximum, and distribution.
 
- With Amazon SageMaker Model Monitor, you can select the data that you would like to monitor and analyze without the need to write any code. You can use SageMaker Model Monitor to select data from a menu of options such as prediction output and sampling percentage. It also captures metadata such as timestamp, model name, and endpoint so that you can analyze model predictions based on the metadata.
- To activate data capture for monitoring and model data quality, you must define and specify a data capture configuration when deploying an endpoint. You specify data capture configuration when you define the predictor. When you invoke the endpoint, the request and response payload, and additional metadata, are saved in the Amazon S3 location that you specified in DataCaptureConfig. The data capture file is stored in JSON-line (JSONL) format. Each inference request is captured in one line in the jsonl file. The line contains both the input and output merged together, along with the ContentType, encoding, and other metadata. Data capture files are organized based on the hour in which the invocation occurred.
- Output data is stored in statistics.json and constraints.json files, even if no violations are identified. Requests and predictions are copied asynchronously from disk to Amazon S3. You can also analyze or visualize results in the output files.
- SageMaker includes a built-in Model Monitor container to analyze CSV and JSON (tabular data) files. It identifies baselines, performs constraint validation against a baseline, and emits CloudWatch metrics. By using this container, your baseline job computes the baseline schema constraints and statistics for each feature. Model Monitor analyzer uses Deequ, an open-source library that is built on Apache Spark, which measures data quality in large datasets. The container stores the baseline statistics in a statistics.json file, and the constraints in a constraints.json file in the pipeline bucket. You can visualize the data set distribution or other baseline statistics by using a notebook
- SageMaker Model Monitor uses SageMaker Clarify to analyze your data and models for bias and explainability. For example, a bias drift monitoring job would first merge captured data and ground truth data, and then compute bias metrics on the merged data. As the model is monitored, you can view exportable reports and graphs detailing bias.
- The SageMaker Lineage graph is a visual representation of the information that is captured by SageMaker Lineage Tracking.
- On Monitoring Use built-in rules unless custom rules are needed. You can use built-in rules to monitor your models or write
your own custom rules. For built-in rules, you get up to 30 hours of monitoring at no charge. Additional charges will be based on duration of usage. You are charged separately when you use your own custom rules.
- Lineage tracking helps you to investigate the pipelines and events that created an artifact. You can use it to track down the cause of an issue. You can also trace subsequent events and artifacts that were created from a problematic artifact. Thus, it helps you to correct issues that might not have been detected yet. You can use the SageMaker Lineage API to locate lineage entities and access their metadata. You use the API to construct queries with filters that define the lineage entities that you want to find.
- Now, imagine discovering that a dataset has an error, and all of the endpoints with models trained using that data must be rolled back. This example uses the lineage API to construct a query that will find all of the endpoints associated with the corrupted dataset. First, you define a filter that looks for contexts that represent endpoints. Specify the focal point of the lineage query by using the start_arns parameter. In this case, it is the Amazon Resource Name (ARN) of the corrupted dataset. Finally, you set the direction of the query. In this case, the direction is set to DESCENDANTS so the query looks for endpoints that use models that were trained on the dataset.




 





























